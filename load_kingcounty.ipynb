{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473e4f54-c3b5-4d40-b5e6-2ac5f186118a",
   "metadata": {},
   "source": [
    "# load_kingcounty\n",
    "\n",
    "Extracts, transforms, and loads various King County marine observations.\n",
    "\n",
    "* [CTD Data](https://green2.kingcounty.gov/marine/Download)\n",
    "* Lab data: available by request from King County\n",
    "* [Mooring Data](https://green2.kingcounty.gov/marine-buoy/Data.aspx) (not implemented yet)\n",
    "* stations file: The CTD download page makes a POST HTTP request to https://green2.kingcounty.gov/marine/Download/GetStations. The file here is the response JSON object from that request, and has been included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf75b2c-3952-4a06-9c68-ea80dc189834",
   "metadata": {},
   "outputs": [],
   "source": [
    "kingcounty_ctd_files = \"data/kingcounty/ctd/*.csv\"\n",
    "kingcounty_nut_files = \"data/kingcounty/nutrients/*.xlsx\"\n",
    "stations_file = \"data/kingcounty/stations.json\"\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import uuid\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4a0a5-6a53-4a88-b90f-92b19332a182",
   "metadata": {},
   "source": [
    "Start by parsing the stations.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ac8e0c-8527-489a-8d21-1d46bba1f0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locator</th>\n",
       "      <th>stationName</th>\n",
       "      <th>stationDesc</th>\n",
       "      <th>depth</th>\n",
       "      <th>sediment</th>\n",
       "      <th>offshore</th>\n",
       "      <th>ctd</th>\n",
       "      <th>ysi</th>\n",
       "      <th>beach</th>\n",
       "      <th>shellfish</th>\n",
       "      <th>active</th>\n",
       "      <th>Data</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adm Inlet-1</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 1</td>\n",
       "      <td>117.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.51034 47.91255)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adm Inlet-2</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.49484 47.91435)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adm Inlet-3</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 3</td>\n",
       "      <td>198.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.48089 47.91586)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adm Inlet-4-C14</td>\n",
       "      <td>Admiralty Inlet</td>\n",
       "      <td>Admiralty Inlet Transect Station 4-C-14</td>\n",
       "      <td>131.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.46619 47.91741)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adm Inlet-5</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.45183 47.91915)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Locator               stationName  \\\n",
       "0      Adm Inlet-1  Admiralty Inlet Transect   \n",
       "1      Adm Inlet-2  Admiralty Inlet Transect   \n",
       "2      Adm Inlet-3  Admiralty Inlet Transect   \n",
       "3  Adm Inlet-4-C14           Admiralty Inlet   \n",
       "4      Adm Inlet-5  Admiralty Inlet Transect   \n",
       "\n",
       "                               stationDesc  depth  sediment  offshore   ctd  \\\n",
       "0       Admiralty Inlet Transect Station 1  117.5     False     False  True   \n",
       "1       Admiralty Inlet Transect Station 2  193.0     False     False  True   \n",
       "2       Admiralty Inlet Transect Station 3  198.5     False     False  True   \n",
       "3  Admiralty Inlet Transect Station 4-C-14  131.5     False      True  True   \n",
       "4       Admiralty Inlet Transect Station 5   60.0     False     False  True   \n",
       "\n",
       "     ysi  beach  shellfish  active Data                     geometry  \n",
       "0  False  False      False   False   []  POINT (-122.51034 47.91255)  \n",
       "1  False  False      False   False   []  POINT (-122.49484 47.91435)  \n",
       "2  False  False      False   False   []  POINT (-122.48089 47.91586)  \n",
       "3  False  False      False   False   []  POINT (-122.46619 47.91741)  \n",
       "4  False  False      False   False   []  POINT (-122.45183 47.91915)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lat/longs in this JSON file appear to be encoded as DDDMMSS.SSS with no cardinality.\n",
    "# This takes a custom function to convert.\n",
    "def to_decdeg(raw):\n",
    "    degs = (raw / 1e4).astype(int)\n",
    "    mins = ((raw - degs * 1e4) / 100).astype(int)\n",
    "    secs = raw - degs * 1e4 - mins * 100\n",
    "    return degs + mins / 60 + secs / 3600\n",
    "\n",
    "with open(stations_file) as f:\n",
    "    station_data = json.load(f)\n",
    "station_df = pd.DataFrame(station_data)\n",
    "# Make a GeoDataFrame for the stations\n",
    "station_gdf = gpd.GeoDataFrame(\n",
    "    station_df.drop(['lat','long'],axis=1),\n",
    "    crs='epsg:6318',\n",
    "    geometry=[Point(xy) for xy in zip(-to_decdeg(station_df.long), to_decdeg(station_df.lat))])\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8eec8f-63bb-47ac-8bda-e68e5b43740a",
   "metadata": {},
   "source": [
    "Clean up the stations GeoDataFrame to match the DB schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0a1fe7-a596-4824-a3c3-c5c3c80b6496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-1</th>\n",
       "      <td>Admiralty Inlet Transect Station 1</td>\n",
       "      <td>POINT (536587.743 5306696.929)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-2</th>\n",
       "      <td>Admiralty Inlet Transect Station 2</td>\n",
       "      <td>POINT (537744.617 5306903.832)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-3</th>\n",
       "      <td>Admiralty Inlet Transect Station 3</td>\n",
       "      <td>POINT (538785.814 5307078.388)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-4-C14</th>\n",
       "      <td>Admiralty Inlet Transect Station 4-C-14</td>\n",
       "      <td>POINT (539883.574 5307258.464)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-5</th>\n",
       "      <td>Admiralty Inlet Transect Station 5</td>\n",
       "      <td>POINT (540954.973 5307459.249)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "name                                                       \n",
       "Adm Inlet-1           Admiralty Inlet Transect Station 1   \n",
       "Adm Inlet-2           Admiralty Inlet Transect Station 2   \n",
       "Adm Inlet-3           Admiralty Inlet Transect Station 3   \n",
       "Adm Inlet-4-C14  Admiralty Inlet Transect Station 4-C-14   \n",
       "Adm Inlet-5           Admiralty Inlet Transect Station 5   \n",
       "\n",
       "                                           geom  \n",
       "name                                             \n",
       "Adm Inlet-1      POINT (536587.743 5306696.929)  \n",
       "Adm Inlet-2      POINT (537744.617 5306903.832)  \n",
       "Adm Inlet-3      POINT (538785.814 5307078.388)  \n",
       "Adm Inlet-4-C14  POINT (539883.574 5307258.464)  \n",
       "Adm Inlet-5      POINT (540954.973 5307459.249)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_gdf = station_gdf[['Locator','stationDesc','geometry']].rename(columns={\n",
    "    \"Locator\": \"name\",\n",
    "    \"stationDesc\": \"description\"\n",
    "}).rename_geometry('geom').to_crs(epsg=32610).set_index('name')\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8076a-35f0-406f-b5d7-1b25648662d1",
   "metadata": {},
   "source": [
    "Save any stations that aren't already in the DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea50bed-1732-4057-a361-4f478ffc1d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RSR837</th>\n",
       "      <td>Strait of Georgia: Rosario Strait - Peapod Rock</td>\n",
       "      <td>POINT (517470.419 5384851.335)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMB006</th>\n",
       "      <td>Commencement Bay - Mouth of City WW</td>\n",
       "      <td>POINT (542614.497 5234397.690)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSE002</th>\n",
       "      <td>Case Inlet - Off Rocky Point</td>\n",
       "      <td>POINT (514099.002 5244447.120)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYE004</th>\n",
       "      <td>Dyes Inlet - NE of Chico Bay</td>\n",
       "      <td>POINT (523419.029 5274483.975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELD001</th>\n",
       "      <td>Eld Inlet - Flapjack Point</td>\n",
       "      <td>POINT (503921.564 5217019.981)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "name                                                      \n",
       "RSR837  Strait of Georgia: Rosario Strait - Peapod Rock   \n",
       "CMB006              Commencement Bay - Mouth of City WW   \n",
       "CSE002                     Case Inlet - Off Rocky Point   \n",
       "DYE004                     Dyes Inlet - NE of Chico Bay   \n",
       "ELD001                       Eld Inlet - Flapjack Point   \n",
       "\n",
       "                                  geom  \n",
       "name                                    \n",
       "RSR837  POINT (517470.419 5384851.335)  \n",
       "CMB006  POINT (542614.497 5234397.690)  \n",
       "CSE002  POINT (514099.002 5244447.120)  \n",
       "DYE004  POINT (523419.029 5274483.975)  \n",
       "ELD001  POINT (503921.564 5217019.981)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = db.connect()\n",
    "locations_existing = gpd.read_postgis('SELECT * FROM obsdata.stations', con=engine, index_col='name')\n",
    "station_gdf = station_gdf.loc[~station_gdf.index.isin(locations_existing.index)]\n",
    "if len(station_gdf) > 0:\n",
    "    station_gdf.to_postgis('stations', con=engine, schema='obsdata', index=True, index_label='name', if_exists='append')\n",
    "    print(f'Loaded {len(station_gdf)} locations')\n",
    "\n",
    "    station_gdf = gpd.read_postgis('SELECT * FROM obsdata.stations', con=engine, index_col='name')\n",
    "else:\n",
    "    station_gdf = locations_existing\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cc59e-0e83-43aa-9ea1-b762dc209571",
   "metadata": {},
   "source": [
    "Create a King County source if it doesn't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7ea697-c6b9-408d-9c45-2bbd5045113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WA Ecology</td>\n",
       "      <td>MarineWater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN201805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN200902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>SH1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>MV1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN200909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>SH1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>AQ201610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>NorsemanII_Oct2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>AQ201710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>BOLD200808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>King County</td>\n",
       "      <td>Marine Monitoring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           agency               study\n",
       "id                                   \n",
       "1      WA Ecology         MarineWater\n",
       "3   Salish Cruise               TN322\n",
       "4   Salish Cruise              CB1023\n",
       "5   Salish Cruise               TN315\n",
       "6   Salish Cruise              CB1050\n",
       "7   Salish Cruise               TN105\n",
       "8   Salish Cruise         RBTSN201805\n",
       "9   Salish Cruise               TN333\n",
       "10  Salish Cruise               TN079\n",
       "11  Salish Cruise              RC0007\n",
       "12  Salish Cruise              CAB897\n",
       "13  Salish Cruise               TN111\n",
       "14  Salish Cruise              CAB101\n",
       "15  Salish Cruise               TN281\n",
       "16  Salish Cruise               TN093\n",
       "17  Salish Cruise               TN164\n",
       "18  Salish Cruise               TN270\n",
       "19  Salish Cruise              RC0022\n",
       "20  Salish Cruise              CB1065\n",
       "21  Salish Cruise              CB1041\n",
       "22  Salish Cruise         RBTSN200902\n",
       "23  Salish Cruise              SH1709\n",
       "24  Salish Cruise              MV1403\n",
       "25  Salish Cruise         RBTSN200909\n",
       "26  Salish Cruise               TN244\n",
       "27  Salish Cruise               TN138\n",
       "28  Salish Cruise               TN301\n",
       "29  Salish Cruise              CAB861\n",
       "30  Salish Cruise              SH1604\n",
       "31  Salish Cruise            AQ201610\n",
       "32  Salish Cruise               TN176\n",
       "33  Salish Cruise              CB1079\n",
       "34  Salish Cruise               TN156\n",
       "35  Salish Cruise               TN128\n",
       "36  Salish Cruise               TN148\n",
       "37  Salish Cruise              CB1019\n",
       "38  Salish Cruise               TN170\n",
       "39  Salish Cruise               TN119\n",
       "40  Salish Cruise               RC001\n",
       "41  Salish Cruise               TN202\n",
       "42  Salish Cruise              CB1045\n",
       "43  Salish Cruise              CAB771\n",
       "44  Salish Cruise              CB1034\n",
       "45  Salish Cruise           RBTSN2017\n",
       "46  Salish Cruise              RC0006\n",
       "47  Salish Cruise               TN097\n",
       "48  Salish Cruise  NorsemanII_Oct2018\n",
       "49  Salish Cruise               TN216\n",
       "50  Salish Cruise               TN296\n",
       "51  Salish Cruise              CB1028\n",
       "52  Salish Cruise            AQ201710\n",
       "53  Salish Cruise              CB1075\n",
       "54  Salish Cruise               TN196\n",
       "55  Salish Cruise               TN256\n",
       "56  Salish Cruise          BOLD200808\n",
       "57  Salish Cruise               TN087\n",
       "58    King County   Marine Monitoring"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_table(\"sources\", con=engine, schema='obsdata', index_col='id')\n",
    "kc_source_row = df.loc[(df['agency'] == \"King County\") & (df['study'] == \"Marine Monitoring\")]\n",
    "if len(kc_source_row) == 0:\n",
    "    df = pd.DataFrame({\n",
    "        \"agency\": [\"King County\"],\n",
    "        \"study\": [\"Marine Monitoring\"]\n",
    "    })\n",
    "    df.to_sql('sources', con=engine, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "    # Refresh the sources so we can fetch the primary key\n",
    "    df = pd.read_sql_table(\"sources\", con=engine, schema='obsdata', index_col='id')\n",
    "    kc_source_row = df.loc[(df['agency'] == \"King County\") & (df['study'] == \"Marine Monitoring\")]\n",
    "\n",
    "kc_source_id = kc_source_row.index[0]\n",
    "print(kc_source_id)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64628a89-9437-443f-b751-73a2e7e28ed5",
   "metadata": {},
   "source": [
    "Read the downloaded CTD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54270bd0-9526-421d-863b-c58d8db2ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = (\n",
    "    (\"temp\",\"Sample_Temperature_field\",1),\n",
    "    (\"o2\",\"DO_field\",1),\n",
    "    (\"chla\",\"Chla_field\",1),\n",
    "    (\"salt\",\"Salinity_field\",1),\n",
    "    (\"no23\",\"NO23_field\",1000/14.01)\n",
    ")\n",
    "\n",
    "# Per-thread database connection\n",
    "def db_init():\n",
    "    global thread_con\n",
    "    thread_con = db.connect()\n",
    "\n",
    "def extract_ctds(f):\n",
    "    # Setting dtypes on the _Qual cols avoids DTypeWarnings\n",
    "    df = pd.read_csv(f, skiprows=1, parse_dates=[1], encoding='utf-16', dtype={\n",
    "        'ST_Qual': str, 'DN_Qual': str, 'DO_Qual': str, 'CH_Qual': str,\n",
    "        'SA_Qual': str, 'LT_Qual': str, 'NO23_Qual': str\n",
    "    })\n",
    "    # Apply the timezone\n",
    "    df[\"Sample_Date\"] = df[\"Sample_Date\"].dt.tz_localize('US/Pacific')\n",
    "\n",
    "    # For each _Qual column, mask any data in the previous column if the _Qual value contains a bad QA flag (R or E)\n",
    "    for i,isqual in enumerate(df.columns.str.endswith(\"_Qual\")):\n",
    "        if not isqual:\n",
    "            continue\n",
    "        data_col = df.columns[i - 1]\n",
    "        qual_col = df.columns[i]\n",
    "        df.loc[df[qual_col].str.contains(\"R\") | df[qual_col].str.contains(\"E\"), data_col] = np.nan\n",
    "        \n",
    "    df.rename(columns={\n",
    "        \"Locator\": \"location_id\",\n",
    "        \"Sample_Date\": \"datetime\",\n",
    "        \"Sample_Depth\": \"depth\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Eliminate any duplicate depth observations by taking the mean of all the\n",
    "    # duplicated measurements\n",
    "    df = df.groupby(['UpDown','location_id','datetime','depth']).mean().reset_index()\n",
    "\n",
    "    # Cast detection so observations can be interpolated:\n",
    "    # See https://stackoverflow.com/a/48975426\n",
    "    df['cast_id'] = 1\n",
    "    df.loc[:, 'cast_id'] = df.groupby(['location_id', pd.Grouper(key='datetime', freq='30min')])['cast_id'].transform(lambda g: uuid.uuid4())\n",
    "    \n",
    "    for dbparam,csvparam, convert in column_map:\n",
    "        if csvparam not in df.columns:\n",
    "            continue\n",
    "        # For each data column, make a view that drops the NaNs, then append\n",
    "        # that view's station, time, depth, and column value to\n",
    "        # outs. Create a filled parameter_id that corresponds to the\n",
    "        # data column and append it as well.\n",
    "        view = df.loc[df['UpDown'] == 'Down'].dropna(subset=csvparam)\n",
    "\n",
    "        processed_data = pd.DataFrame({\n",
    "            'datetime': view['datetime'],\n",
    "            'depth': view['depth'],\n",
    "            'value': view[csvparam] * convert,\n",
    "            'location_id': view['location_id'],\n",
    "            'cast_id': view['cast_id']\n",
    "        })\n",
    "        processed_data['source_id'] = kc_source_id\n",
    "        processed_data['parameter_id'] = dbparam\n",
    "        # Remove any cast IDs for parameters that were measured fewer than 5 times\n",
    "        # (these cannot be interpolated reliably)\n",
    "        counts = processed_data[['cast_id','parameter_id','value']].groupby(['cast_id','parameter_id']).count()\n",
    "        m = processed_data.merge(counts, how='left', left_on=('cast_id','parameter_id'), right_index=True)\n",
    "        processed_data.loc[m['value_y'] < 5, 'cast_id'] = np.nan\n",
    "\n",
    "        processed_data.to_sql('observations', con=thread_con, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "with Pool(initializer=db_init) as p:\n",
    "    p.map(extract_ctds, glob.glob(kingcounty_ctd_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e3a9b-6398-4a1a-a954-5a3a440e6dfb",
   "metadata": {},
   "source": [
    "Now read the nutrient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35eff30-c1d6-4cec-a218-95147f16d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_map = pd.DataFrame((\n",
    "    (\"sioh4\",\"Silica\",1000/28.09),\n",
    "    (\"nh4\",\"Ammonia Nitrogen\",1000/14.01),\n",
    "    (\"no23\",\"Nitrite + Nitrate Nitrogen\",1000/14.01),\n",
    "    (\"orthp\",\"Orthophosphate Phosphorus\", 1000/30.97)\n",
    "), columns=(\"dbparam\",\"kcparam\",\"conv\"))\n",
    "\n",
    "def extract_nutrients(f):\n",
    "    df = pd.read_excel(f, parse_dates=[1])\n",
    "    # Apply the timezone\n",
    "    df[\"Collect DateTime\"] = df[\"Collect DateTime\"].dt.tz_localize('US/Pacific')\n",
    "\n",
    "    # Not all entries have times filled in on the dates. Need to apply a non-midnight times found to\n",
    "    # the midnight times for matching dates.\n",
    "    # From examining the data I've been given, it looks like there's usually at least one row with\n",
    "    # an actual time for a given location and date. So group by location/date and find a non-midnight\n",
    "    # time (using max()), merge that time back into the DataFrame, and substitute it for all rows that\n",
    "    # have a midnight time.\n",
    "    df['date'] = df[\"Collect DateTime\"].dt.date\n",
    "    date_times = df.groupby([\"Locator\",\"date\"])[\"Collect DateTime\"].max()\n",
    "    df = df.merge(date_times, left_on=[\"Locator\",\"date\"], right_index=True)\n",
    "    df.loc[df[\"Collect DateTime_x\"].dt.hour == 0, \"Collect DateTime_x\"] = df[\"Collect DateTime_y\"]\n",
    "\n",
    "    # Eliminate data that does not pass QA\n",
    "    qa_fails = ('<MDL','E','H','SH','R')\n",
    "    # Assemble an indexer by splitting the qualifier comma-delimited list and expanding\n",
    "    # it into multiple columns. Bitwise-AND the indexer with a negated isin() check of\n",
    "    # each column to ensure that the column does not contain a QA failure flag.\n",
    "    qa_data = df['Lab Qualifier'].astype(str)\n",
    "    qa_vals = qa_data.str.split(',', expand=True)\n",
    "    indexer = True\n",
    "    for i,col in enumerate(qa_vals.columns):\n",
    "        indexer &= ~qa_vals[i].isin(qa_fails)\n",
    "    df = df.loc[indexer].dropna(subset='Value')\n",
    "\n",
    "    # Merge with the parameter map to get the parameter_id\n",
    "    df = df.merge(parameter_map, how='inner', left_on='Parameter', right_on='kcparam').rename(\n",
    "        columns={'Collect DateTime_x': 'datetime', 'Depth (m)': 'depth',\n",
    "                 'Locator': 'location_id', 'Value': 'value', 'dbparam': 'parameter_id' }\n",
    "    )[['datetime','depth','location_id','value','parameter_id']]\n",
    "    df['source_id'] = kc_source_id\n",
    "\n",
    "    # Eliminate any duplicate depth observations by taking the mean of all the\n",
    "    # duplicated measurements\n",
    "    df = df.groupby(['location_id','datetime','depth','parameter_id']).mean().reset_index()\n",
    "\n",
    "    # Prevent unique constraint violations from lab vs CTD NO23 values by adding a minute\n",
    "    # to the dates.\n",
    "    df['datetime'] += pd.to_timedelta(1, 'min')\n",
    "    \n",
    "    # Perform unit conversions\n",
    "    for i,row in parameter_map.iterrows():\n",
    "        df.loc[df['parameter_id'] == row['dbparam'], 'value'] *= row['conv']\n",
    "\n",
    "    df.to_sql('observations', con=thread_con, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "thread_con = engine\n",
    "for f in glob.glob(kingcounty_nut_files):\n",
    "    extract_nutrients(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e650f-d235-411f-82dd-0ecb9e7db7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:puget_sound_obs_data]",
   "language": "python",
   "name": "conda-env-puget_sound_obs_data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
