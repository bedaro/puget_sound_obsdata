{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473e4f54-c3b5-4d40-b5e6-2ac5f186118a",
   "metadata": {},
   "source": [
    "# load_kingcounty\n",
    "\n",
    "Extracts, transforms, and loads various King County marine observations.\n",
    "\n",
    "* [CTD Data](https://green2.kingcounty.gov/marine/Download)\n",
    "* Lab data: available by request from King County. May also be directly available from https://data.kingcounty.gov/Environment-Waste-Management/Water-Quality/vwmt-pvjw/data\n",
    "* [Mooring Data](https://green2.kingcounty.gov/marine-buoy/Data.aspx) Select Depth, Water Temperature, Salinity, Dissolved Oxygen, Fluorescence, Nitrate+Nitrite (FINAL), SeaFET external pH (FINAL). Download as text.\n",
    "* stations file: The CTD download page makes a POST HTTP request to https://green2.kingcounty.gov/marine/Download/GetStations. The file here is the response JSON object from that request, and has been included in the repository.\n",
    "* moorings file: The [KC Moorings Home page](https://green2.kingcounty.gov/marine-buoy/default.aspx) contains a hidden element in the HTML containing the information for all the mooring locations. The file here is the value of that hidden element; semicolons replaced with newlines for easier parsing. The column specs are reverse engineering from the JavaScript function that parses this data on the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf75b2c-3952-4a06-9c68-ea80dc189834",
   "metadata": {},
   "outputs": [],
   "source": [
    "kingcounty_ctd_files = \"data/kingcounty/ctd/*.csv\"\n",
    "kingcounty_nut_files = \"data/kingcounty/nutrients/*.xlsx\"\n",
    "kingcounty_mooring_files = \"data/kingcounty/mooring/*.txt\"\n",
    "stations_file = \"data/kingcounty/stations.json\"\n",
    "moorings_file = \"data/kingcounty/moorings.txt\"\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4a0a5-6a53-4a88-b90f-92b19332a182",
   "metadata": {},
   "source": [
    "Start by parsing the stations.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ac8e0c-8527-489a-8d21-1d46bba1f0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locator</th>\n",
       "      <th>stationName</th>\n",
       "      <th>stationDesc</th>\n",
       "      <th>depth</th>\n",
       "      <th>sediment</th>\n",
       "      <th>offshore</th>\n",
       "      <th>ctd</th>\n",
       "      <th>ysi</th>\n",
       "      <th>beach</th>\n",
       "      <th>shellfish</th>\n",
       "      <th>active</th>\n",
       "      <th>Data</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adm Inlet-1</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 1</td>\n",
       "      <td>117.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.51034 47.91255)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adm Inlet-2</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 2</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.49484 47.91435)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adm Inlet-3</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 3</td>\n",
       "      <td>198.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.48089 47.91586)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adm Inlet-4-C14</td>\n",
       "      <td>Admiralty Inlet</td>\n",
       "      <td>Admiralty Inlet Transect Station 4-C-14</td>\n",
       "      <td>131.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.46619 47.91741)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adm Inlet-5</td>\n",
       "      <td>Admiralty Inlet Transect</td>\n",
       "      <td>Admiralty Inlet Transect Station 5</td>\n",
       "      <td>60.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>POINT (-122.45183 47.91915)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Locator               stationName  \\\n",
       "0      Adm Inlet-1  Admiralty Inlet Transect   \n",
       "1      Adm Inlet-2  Admiralty Inlet Transect   \n",
       "2      Adm Inlet-3  Admiralty Inlet Transect   \n",
       "3  Adm Inlet-4-C14           Admiralty Inlet   \n",
       "4      Adm Inlet-5  Admiralty Inlet Transect   \n",
       "\n",
       "                               stationDesc  depth  sediment  offshore   ctd  \\\n",
       "0       Admiralty Inlet Transect Station 1  117.5     False     False  True   \n",
       "1       Admiralty Inlet Transect Station 2  193.0     False     False  True   \n",
       "2       Admiralty Inlet Transect Station 3  198.5     False     False  True   \n",
       "3  Admiralty Inlet Transect Station 4-C-14  131.5     False      True  True   \n",
       "4       Admiralty Inlet Transect Station 5   60.0     False     False  True   \n",
       "\n",
       "     ysi  beach  shellfish  active Data                     geometry  \n",
       "0  False  False      False   False   []  POINT (-122.51034 47.91255)  \n",
       "1  False  False      False   False   []  POINT (-122.49484 47.91435)  \n",
       "2  False  False      False   False   []  POINT (-122.48089 47.91586)  \n",
       "3  False  False      False   False   []  POINT (-122.46619 47.91741)  \n",
       "4  False  False      False   False   []  POINT (-122.45183 47.91915)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lat/longs in this JSON file appear to be encoded as DDDMMSS.SSS with no cardinality.\n",
    "# This takes a custom function to convert.\n",
    "def to_decdeg(raw):\n",
    "    degs = (raw / 1e4).astype(int)\n",
    "    mins = ((raw - degs * 1e4) / 100).astype(int)\n",
    "    secs = raw - degs * 1e4 - mins * 100\n",
    "    return degs + mins / 60 + secs / 3600\n",
    "\n",
    "with open(stations_file) as f:\n",
    "    station_data = json.load(f)\n",
    "station_df = pd.DataFrame(station_data)\n",
    "# Make a GeoDataFrame for the stations\n",
    "station_gdf = gpd.GeoDataFrame(\n",
    "    station_df.drop(['lat','long'],axis=1),\n",
    "    crs='epsg:6318',\n",
    "    geometry=[Point(xy) for xy in zip(-to_decdeg(station_df.long), to_decdeg(station_df.lat))])\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8eec8f-63bb-47ac-8bda-e68e5b43740a",
   "metadata": {},
   "source": [
    "Clean up the stations GeoDataFrame to match the DB schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0a1fe7-a596-4824-a3c3-c5c3c80b6496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-1</th>\n",
       "      <td>Admiralty Inlet Transect Station 1</td>\n",
       "      <td>POINT (536587.743 5306696.929)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-2</th>\n",
       "      <td>Admiralty Inlet Transect Station 2</td>\n",
       "      <td>POINT (537744.617 5306903.832)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-3</th>\n",
       "      <td>Admiralty Inlet Transect Station 3</td>\n",
       "      <td>POINT (538785.814 5307078.388)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-4-C14</th>\n",
       "      <td>Admiralty Inlet Transect Station 4-C-14</td>\n",
       "      <td>POINT (539883.574 5307258.464)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-5</th>\n",
       "      <td>Admiralty Inlet Transect Station 5</td>\n",
       "      <td>POINT (540954.973 5307459.249)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "name                                                       \n",
       "Adm Inlet-1           Admiralty Inlet Transect Station 1   \n",
       "Adm Inlet-2           Admiralty Inlet Transect Station 2   \n",
       "Adm Inlet-3           Admiralty Inlet Transect Station 3   \n",
       "Adm Inlet-4-C14  Admiralty Inlet Transect Station 4-C-14   \n",
       "Adm Inlet-5           Admiralty Inlet Transect Station 5   \n",
       "\n",
       "                                           geom  \n",
       "name                                             \n",
       "Adm Inlet-1      POINT (536587.743 5306696.929)  \n",
       "Adm Inlet-2      POINT (537744.617 5306903.832)  \n",
       "Adm Inlet-3      POINT (538785.814 5307078.388)  \n",
       "Adm Inlet-4-C14  POINT (539883.574 5307258.464)  \n",
       "Adm Inlet-5      POINT (540954.973 5307459.249)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_gdf = station_gdf[['Locator','stationDesc','geometry']].rename(columns={\n",
    "    \"Locator\": \"name\",\n",
    "    \"stationDesc\": \"description\"\n",
    "}).rename_geometry('geom').to_crs(epsg=32610).set_index('name')\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab531d1-bbec-4776-a7ba-157a6cf61ced",
   "metadata": {},
   "source": [
    "Add the moorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facab845-ff5a-48b4-9744-920e8c939fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dockton</th>\n",
       "      <td>Dockton Park</td>\n",
       "      <td>POINT (541267.236 5246741.441)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuartermasterBuoy</th>\n",
       "      <td>Quartermaster Buoy</td>\n",
       "      <td>POINT (539340.975 5242856.523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrightwaterBuoy</th>\n",
       "      <td>Brightwater Buoy</td>\n",
       "      <td>POINT (545019.662 5291892.864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AlkiBuoy</th>\n",
       "      <td>Alki Buoy</td>\n",
       "      <td>POINT (543470.650 5268680.701)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuartermasterYachtClub</th>\n",
       "      <td>Quartermaster Yacht Club</td>\n",
       "      <td>POINT (540486.695 5249113.604)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     description  \\\n",
       "name                                               \n",
       "Dockton                             Dockton Park   \n",
       "QuartermasterBuoy             Quartermaster Buoy   \n",
       "BrightwaterBuoy                 Brightwater Buoy   \n",
       "AlkiBuoy                               Alki Buoy   \n",
       "QuartermasterYachtClub  Quartermaster Yacht Club   \n",
       "\n",
       "                                                  geom  \n",
       "name                                                    \n",
       "Dockton                 POINT (541267.236 5246741.441)  \n",
       "QuartermasterBuoy       POINT (539340.975 5242856.523)  \n",
       "BrightwaterBuoy         POINT (545019.662 5291892.864)  \n",
       "AlkiBuoy                POINT (543470.650 5268680.701)  \n",
       "QuartermasterYachtClub  POINT (540486.695 5249113.604)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mooring_df = pd.read_csv(moorings_file, sep='\\t', header=0, names=('description','lat','long','active','buoy','site_id','name'), index_col='site_id')\n",
    "# Make a GeoDataFrame for the moorings\n",
    "mooring_gdf = gpd.GeoDataFrame(\n",
    "    mooring_df.drop(['lat','long','active','buoy'],axis=1),\n",
    "    crs='epsg:6318',\n",
    "    geometry=[Point(xy) for xy in zip(mooring_df.long, mooring_df.lat)])\n",
    "mooring_gdf = mooring_gdf[['name','description','geometry']]\\\n",
    "    .rename_geometry('geom').set_index('name').to_crs(epsg=32610)\n",
    "mooring_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05265745-30f8-4054-b38c-b250ae377879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-1</th>\n",
       "      <td>Admiralty Inlet Transect Station 1</td>\n",
       "      <td>POINT (536587.743 5306696.929)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-2</th>\n",
       "      <td>Admiralty Inlet Transect Station 2</td>\n",
       "      <td>POINT (537744.617 5306903.832)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-3</th>\n",
       "      <td>Admiralty Inlet Transect Station 3</td>\n",
       "      <td>POINT (538785.814 5307078.388)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-4-C14</th>\n",
       "      <td>Admiralty Inlet Transect Station 4-C-14</td>\n",
       "      <td>POINT (539883.574 5307258.464)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adm Inlet-5</th>\n",
       "      <td>Admiralty Inlet Transect Station 5</td>\n",
       "      <td>POINT (540954.973 5307459.249)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             description  \\\n",
       "name                                                       \n",
       "Adm Inlet-1           Admiralty Inlet Transect Station 1   \n",
       "Adm Inlet-2           Admiralty Inlet Transect Station 2   \n",
       "Adm Inlet-3           Admiralty Inlet Transect Station 3   \n",
       "Adm Inlet-4-C14  Admiralty Inlet Transect Station 4-C-14   \n",
       "Adm Inlet-5           Admiralty Inlet Transect Station 5   \n",
       "\n",
       "                                           geom  \n",
       "name                                             \n",
       "Adm Inlet-1      POINT (536587.743 5306696.929)  \n",
       "Adm Inlet-2      POINT (537744.617 5306903.832)  \n",
       "Adm Inlet-3      POINT (538785.814 5307078.388)  \n",
       "Adm Inlet-4-C14  POINT (539883.574 5307258.464)  \n",
       "Adm Inlet-5      POINT (540954.973 5307459.249)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See https://gis.stackexchange.com/a/162661\n",
    "station_gdf = gpd.GeoDataFrame(pd.concat((station_gdf, mooring_gdf))).set_geometry('geom').set_crs(station_gdf.crs)\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca1747-1d65-474c-98e0-54ae8387db75",
   "metadata": {},
   "source": [
    "Save any stations that aren't already in the DB table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea50bed-1732-4057-a361-4f478ffc1d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 locations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RSR837</th>\n",
       "      <td>Strait of Georgia: Rosario Strait - Peapod Rock</td>\n",
       "      <td>POINT (517470.419 5384851.335)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMB006</th>\n",
       "      <td>Commencement Bay - Mouth of City WW</td>\n",
       "      <td>POINT (542614.497 5234397.690)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSE002</th>\n",
       "      <td>Case Inlet - Off Rocky Point</td>\n",
       "      <td>POINT (514099.002 5244447.120)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DYE004</th>\n",
       "      <td>Dyes Inlet - NE of Chico Bay</td>\n",
       "      <td>POINT (523419.029 5274483.975)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELD001</th>\n",
       "      <td>Eld Inlet - Flapjack Point</td>\n",
       "      <td>POINT (503921.564 5217019.981)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "name                                                      \n",
       "RSR837  Strait of Georgia: Rosario Strait - Peapod Rock   \n",
       "CMB006              Commencement Bay - Mouth of City WW   \n",
       "CSE002                     Case Inlet - Off Rocky Point   \n",
       "DYE004                     Dyes Inlet - NE of Chico Bay   \n",
       "ELD001                       Eld Inlet - Flapjack Point   \n",
       "\n",
       "                                  geom  \n",
       "name                                    \n",
       "RSR837  POINT (517470.419 5384851.335)  \n",
       "CMB006  POINT (542614.497 5234397.690)  \n",
       "CSE002  POINT (514099.002 5244447.120)  \n",
       "DYE004  POINT (523419.029 5274483.975)  \n",
       "ELD001  POINT (503921.564 5217019.981)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = db.connect()\n",
    "locations_existing = gpd.read_postgis('SELECT * FROM obsdata.stations', con=engine, index_col='name')\n",
    "station_gdf = station_gdf.loc[~station_gdf.index.isin(locations_existing.index)]\n",
    "if len(station_gdf) > 0:\n",
    "    station_gdf.to_postgis('stations', con=engine, schema='obsdata', index=True, index_label='name', if_exists='append')\n",
    "    print(f'Loaded {len(station_gdf)} locations')\n",
    "\n",
    "    station_gdf = gpd.read_postgis('SELECT * FROM obsdata.stations', con=engine, index_col='name')\n",
    "else:\n",
    "    station_gdf = locations_existing\n",
    "station_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cc59e-0e83-43aa-9ea1-b762dc209571",
   "metadata": {},
   "source": [
    "Create a King County source if it doesn't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7ea697-c6b9-408d-9c45-2bbd5045113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>study</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WA Ecology</td>\n",
       "      <td>MarineWater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>King County</td>\n",
       "      <td>Marine Monitoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN201805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN200902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>SH1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>MV1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN200909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>SH1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>AQ201610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CAB771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RBTSN2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>RC0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>NorsemanII_Oct2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>AQ201710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>CB1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>BOLD200808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Salish Cruise</td>\n",
       "      <td>TN087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            agency               study\n",
       "id                                    \n",
       "1       WA Ecology         MarineWater\n",
       "169  Salish Cruise               TN322\n",
       "58     King County   Marine Monitoring\n",
       "170  Salish Cruise              CB1023\n",
       "171  Salish Cruise               TN315\n",
       "172  Salish Cruise              CB1050\n",
       "173  Salish Cruise               TN105\n",
       "174  Salish Cruise         RBTSN201805\n",
       "175  Salish Cruise               TN333\n",
       "176  Salish Cruise               TN079\n",
       "177  Salish Cruise              RC0007\n",
       "178  Salish Cruise              CAB897\n",
       "179  Salish Cruise               TN111\n",
       "180  Salish Cruise              CAB101\n",
       "181  Salish Cruise               TN281\n",
       "182  Salish Cruise               TN093\n",
       "183  Salish Cruise               TN164\n",
       "184  Salish Cruise               TN270\n",
       "185  Salish Cruise              RC0022\n",
       "186  Salish Cruise              CB1065\n",
       "187  Salish Cruise              CB1041\n",
       "188  Salish Cruise         RBTSN200902\n",
       "189  Salish Cruise              SH1709\n",
       "190  Salish Cruise              MV1403\n",
       "191  Salish Cruise         RBTSN200909\n",
       "192  Salish Cruise               TN244\n",
       "193  Salish Cruise               TN138\n",
       "194  Salish Cruise               TN301\n",
       "195  Salish Cruise              CAB861\n",
       "196  Salish Cruise              SH1604\n",
       "197  Salish Cruise            AQ201610\n",
       "198  Salish Cruise               TN176\n",
       "199  Salish Cruise              CB1079\n",
       "200  Salish Cruise               TN156\n",
       "201  Salish Cruise               TN128\n",
       "202  Salish Cruise               TN148\n",
       "203  Salish Cruise              CB1019\n",
       "204  Salish Cruise               TN170\n",
       "205  Salish Cruise               TN119\n",
       "206  Salish Cruise               RC001\n",
       "207  Salish Cruise               TN202\n",
       "208  Salish Cruise              CB1045\n",
       "209  Salish Cruise              CAB771\n",
       "210  Salish Cruise              CB1034\n",
       "211  Salish Cruise           RBTSN2017\n",
       "212  Salish Cruise              RC0006\n",
       "213  Salish Cruise               TN097\n",
       "214  Salish Cruise  NorsemanII_Oct2018\n",
       "215  Salish Cruise               TN216\n",
       "216  Salish Cruise               TN296\n",
       "217  Salish Cruise              CB1028\n",
       "218  Salish Cruise            AQ201710\n",
       "219  Salish Cruise              CB1075\n",
       "220  Salish Cruise               TN196\n",
       "221  Salish Cruise               TN256\n",
       "222  Salish Cruise          BOLD200808\n",
       "223  Salish Cruise               TN087"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_table(\"sources\", con=engine, schema='obsdata', index_col='id')\n",
    "kc_source_row = df.loc[(df['agency'] == \"King County\") & (df['study'] == \"Marine Monitoring\")]\n",
    "if len(kc_source_row) == 0:\n",
    "    df = pd.DataFrame({\n",
    "        \"agency\": [\"King County\"],\n",
    "        \"study\": [\"Marine Monitoring\"]\n",
    "    })\n",
    "    df.to_sql('sources', con=engine, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "    # Refresh the sources so we can fetch the primary key\n",
    "    df = pd.read_sql_table(\"sources\", con=engine, schema='obsdata', index_col='id')\n",
    "    kc_source_row = df.loc[(df['agency'] == \"King County\") & (df['study'] == \"Marine Monitoring\")]\n",
    "\n",
    "kc_source_id = kc_source_row.index[0]\n",
    "print(kc_source_id)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64628a89-9437-443f-b751-73a2e7e28ed5",
   "metadata": {},
   "source": [
    "Read the downloaded CTD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bfaed1c-89d3-494c-9fba-99bfae12c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-thread database connection\n",
    "def db_init():\n",
    "    global thread_con\n",
    "    thread_con = db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043b7b1b-eba4-46b6-9996-f968bd973875",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = (\n",
    "    (\"temp\",\"Sample_Temperature_field\",1),\n",
    "    (\"o2\",\"DO_field\",1),\n",
    "    (\"chla\",\"Chla_field\",1),\n",
    "    (\"salt\",\"Salinity_field\",1),\n",
    "    (\"no23\",\"NO23_field\",1000/14.01)\n",
    ")\n",
    "\n",
    "def extract_ctds(f):\n",
    "    # Setting dtypes on the _Qual cols avoids DTypeWarnings\n",
    "    df = pd.read_csv(f, skiprows=1, parse_dates=[1], encoding='utf-16', dtype={\n",
    "        'ST_Qual': str, 'DN_Qual': str, 'DO_Qual': str, 'CH_Qual': str,\n",
    "        'SA_Qual': str, 'LT_Qual': str, 'NO23_Qual': str\n",
    "    })\n",
    "    # Apply the timezone\n",
    "    df[\"Sample_Date\"] = df[\"Sample_Date\"].dt.tz_localize('US/Pacific')\n",
    "\n",
    "    # For each _Qual column, mask any data in the previous column if the _Qual value contains a bad QA flag (R or E)\n",
    "    for i,isqual in enumerate(df.columns.str.endswith(\"_Qual\")):\n",
    "        if not isqual:\n",
    "            continue\n",
    "        data_col = df.columns[i - 1]\n",
    "        qual_col = df.columns[i]\n",
    "        df.loc[df[qual_col].str.contains(\"R\") | df[qual_col].str.contains(\"E\"), data_col] = np.nan\n",
    "        \n",
    "    df.rename(columns={\n",
    "        \"Locator\": \"location_id\",\n",
    "        \"Sample_Date\": \"datetime\",\n",
    "        \"Sample_Depth\": \"depth\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Eliminate any duplicate depth observations by taking the mean of all the\n",
    "    # duplicated measurements\n",
    "    df = df.groupby(['UpDown','location_id','datetime','depth']).mean().reset_index()\n",
    "\n",
    "    # Cast detection so observations can be interpolated:\n",
    "    # See https://stackoverflow.com/a/48975426\n",
    "    df['cast_id'] = 1\n",
    "    df.loc[:, 'cast_id'] = df.groupby(['location_id', pd.Grouper(key='datetime', freq='30min')])['cast_id'].transform(lambda g: uuid.uuid4())\n",
    "    \n",
    "    for dbparam,csvparam, convert in column_map:\n",
    "        if csvparam not in df.columns:\n",
    "            continue\n",
    "        # For each data column, make a view that drops the NaNs, then append\n",
    "        # that view's station, time, depth, and column value to\n",
    "        # outs. Create a filled parameter_id that corresponds to the\n",
    "        # data column and append it as well.\n",
    "        view = df.loc[df['UpDown'] == 'Down'].dropna(subset=csvparam)\n",
    "\n",
    "        processed_data = pd.DataFrame({\n",
    "            'datetime': view['datetime'],\n",
    "            'depth': view['depth'],\n",
    "            'value': view[csvparam] * convert,\n",
    "            'location_id': view['location_id'],\n",
    "            'cast_id': view['cast_id']\n",
    "        })\n",
    "        processed_data['source_id'] = kc_source_id\n",
    "        processed_data['parameter_id'] = dbparam\n",
    "        # Remove any cast IDs for parameters that were measured fewer than 5 times\n",
    "        # (these cannot be interpolated reliably)\n",
    "        counts = processed_data[['cast_id','parameter_id','value']].groupby(['cast_id','parameter_id']).count()\n",
    "        m = processed_data.merge(counts, how='left', left_on=('cast_id','parameter_id'), right_index=True)\n",
    "        processed_data.loc[m['value_y'] < 5, 'cast_id'] = np.nan\n",
    "\n",
    "        processed_data.to_sql('observations', con=thread_con, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "with Pool(initializer=db_init) as p:\n",
    "    p.map(extract_ctds, glob.glob(kingcounty_ctd_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e3a9b-6398-4a1a-a954-5a3a440e6dfb",
   "metadata": {},
   "source": [
    "Now read the nutrient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35eff30-c1d6-4cec-a218-95147f16d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_map = pd.DataFrame((\n",
    "    (\"sioh4\",\"Silica\",1000/28.09),\n",
    "    (\"nh4\",\"Ammonia Nitrogen\",1000/14.01),\n",
    "    (\"no23\",\"Nitrite + Nitrate Nitrogen\",1000/14.01),\n",
    "    (\"orthp\",\"Orthophosphate Phosphorus\", 1000/30.97)\n",
    "), columns=(\"dbparam\",\"kcparam\",\"conv\"))\n",
    "\n",
    "def extract_nutrients(f):\n",
    "    df = pd.read_excel(f, parse_dates=[1])\n",
    "    # Apply the timezone\n",
    "    df[\"Collect DateTime\"] = df[\"Collect DateTime\"].dt.tz_localize('US/Pacific')\n",
    "\n",
    "    # Not all entries have times filled in on the dates. Need to apply a non-midnight times found to\n",
    "    # the midnight times for matching dates.\n",
    "    # From examining the data I've been given, it looks like there's usually at least one row with\n",
    "    # an actual time for a given location and date. So group by location/date and find a non-midnight\n",
    "    # time (using max()), merge that time back into the DataFrame, and substitute it for all rows that\n",
    "    # have a midnight time.\n",
    "    df['date'] = df[\"Collect DateTime\"].dt.date\n",
    "    date_times = df.groupby([\"Locator\",\"date\"])[\"Collect DateTime\"].max()\n",
    "    df = df.merge(date_times, left_on=[\"Locator\",\"date\"], right_index=True)\n",
    "    df.loc[df[\"Collect DateTime_x\"].dt.hour == 0, \"Collect DateTime_x\"] = df[\"Collect DateTime_y\"]\n",
    "\n",
    "    # Eliminate data that does not pass QA\n",
    "    qa_fails = ('<MDL','E','H','SH','R')\n",
    "    # Assemble an indexer by splitting the qualifier comma-delimited list and expanding\n",
    "    # it into multiple columns. Bitwise-AND the indexer with a negated isin() check of\n",
    "    # each column to ensure that the column does not contain a QA failure flag.\n",
    "    qa_data = df['Lab Qualifier'].astype(str)\n",
    "    qa_vals = qa_data.str.split(',', expand=True)\n",
    "    indexer = True\n",
    "    for i,col in enumerate(qa_vals.columns):\n",
    "        indexer &= ~qa_vals[i].isin(qa_fails)\n",
    "    df = df.loc[indexer].dropna(subset='Value')\n",
    "\n",
    "    # Merge with the parameter map to get the parameter_id\n",
    "    df = df.merge(parameter_map, how='inner', left_on='Parameter', right_on='kcparam').rename(\n",
    "        columns={'Collect DateTime_x': 'datetime', 'Depth (m)': 'depth',\n",
    "                 'Locator': 'location_id', 'Value': 'value', 'dbparam': 'parameter_id' }\n",
    "    )[['datetime','depth','location_id','value','parameter_id']]\n",
    "    df['source_id'] = kc_source_id\n",
    "\n",
    "    # Eliminate any duplicate depth observations by taking the mean of all the\n",
    "    # duplicated measurements\n",
    "    df = df.groupby(['location_id','datetime','depth','parameter_id']).mean().reset_index()\n",
    "\n",
    "    # Prevent unique constraint violations from lab vs CTD NO23 values by adding a minute\n",
    "    # to the dates.\n",
    "    df['datetime'] += pd.to_timedelta(1, 'min')\n",
    "    \n",
    "    # Perform unit conversions\n",
    "    for i,row in parameter_map.iterrows():\n",
    "        df.loc[df['parameter_id'] == row['dbparam'], 'value'] *= row['conv']\n",
    "\n",
    "    df.to_sql('observations', con=thread_con, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "thread_con = engine\n",
    "for f in glob.glob(kingcounty_nut_files):\n",
    "    extract_nutrients(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18971cf-6a90-4ee5-9c86-ce890b2541f9",
   "metadata": {},
   "source": [
    "Extract the mooring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74a4de1-035d-4b73-be3e-52d8f816c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974609/3789809956.py:11: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_table(f, comment='*', encoding='Windows-1252', parse_dates=[0])\n"
     ]
    }
   ],
   "source": [
    "mooring_column_map = (\n",
    "    (\"temp\",\"Water_Temperature_degC\",1),\n",
    "    (\"o2\",\"Dissolved_Oxygen_mg/L\",1),\n",
    "    (\"chla\",\"Chlorophyll_Fluorescence_ug/L\",1),\n",
    "    (\"salt\",\"Salinity_PSU\",1),\n",
    "    (\"no23\",\"SUNA_Nitrite+Nitrate_mgN/L_final\",1000/14.01),\n",
    "    (\"ph\",\"SeaFET_External_pH_final_recalc\",1)\n",
    ")\n",
    "\n",
    "def extract_mooring(f):\n",
    "    df = pd.read_table(f, comment='*', encoding='Windows-1252', parse_dates=[0])\n",
    "    # Apply the timezone, constant 8 hour offset assumed (waiting to hear back from Kim)\n",
    "    df[\"Date\"] = df[\"Date\"].dt.tz_localize(-8*3600)\n",
    "    \n",
    "    # The station ID for this mooring comes from the file name; whatever is before the first underscore\n",
    "    station_id = os.path.basename(f).split('_')[0]\n",
    "    \n",
    "    # Cast detection so observations can be interpolated:\n",
    "    # See https://stackoverflow.com/a/48975426\n",
    "    df['cast_id'] = 1\n",
    "    df.loc[:, 'cast_id'] = df.groupby('Date')['cast_id'].transform(lambda g: uuid.uuid4())\n",
    "\n",
    "    # Data downloaded should be FINAL, so no QA filtering is needed\n",
    "    df.dropna(subset='Depth_m', inplace=True)\n",
    "\n",
    "    for dbparam,rawparam, convert in mooring_column_map:\n",
    "        if rawparam not in df.columns:\n",
    "            continue\n",
    "        # For each data column, make a view that drops the NaNs, then append\n",
    "        # that view's station, time, depth, and column value to\n",
    "        # outs. Create a filled parameter_id that corresponds to the\n",
    "        # data column and append it as well.\n",
    "        view = df.dropna(subset=rawparam)\n",
    "\n",
    "        processed_data = pd.DataFrame({\n",
    "            'datetime': view['Date'],\n",
    "            'depth': view['Depth_m'],\n",
    "            'value': view[rawparam] * convert,\n",
    "            'cast_id': view['cast_id']\n",
    "        })\n",
    "        processed_data['source_id'] = kc_source_id\n",
    "        processed_data['parameter_id'] = dbparam\n",
    "        processed_data['location_id'] = station_id\n",
    "        # Remove any cast IDs for parameters that were measured fewer than 5 times\n",
    "        # (these cannot be interpolated reliably)\n",
    "        counts = processed_data[['cast_id','parameter_id','value']].groupby(['cast_id','parameter_id']).count()\n",
    "        m = processed_data.merge(counts, how='left', left_on=('cast_id','parameter_id'), right_index=True)\n",
    "        processed_data.loc[m['value_y'] < 5, 'cast_id'] = np.nan\n",
    "\n",
    "        processed_data.to_sql('observations', con=thread_con, schema='obsdata', index=False, if_exists='append')\n",
    "\n",
    "with Pool(initializer=db_init) as p:\n",
    "    p.map(extract_mooring, glob.glob(kingcounty_mooring_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195caa87-3e71-40f9-bd91-cb997ffb3c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:puget_sound_obs_data]",
   "language": "python",
   "name": "conda-env-puget_sound_obs_data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
